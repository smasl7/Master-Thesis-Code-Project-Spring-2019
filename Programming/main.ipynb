{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"eoqekeQBcIXL","colab_type":"code","outputId":"9711460c-cb53-4c9e-adaf-5ff2b5ac0b26","executionInfo":{"status":"ok","timestamp":1552995083921,"user_tz":-60,"elapsed":19399,"user":{"displayName":"Sylwester Liljegren","photoUrl":"","userId":"12611084800088710033"}},"colab":{"base_uri":"https://localhost:8080/","height":1997}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from html import unescape\n","from matplotlib import pyplot as plt\n","from collections import Counter, defaultdict\n","\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","from keras.preprocessing.text import Tokenizer\n","from keras.callbacks import EarlyStopping\n","from keras.models import Sequential\n","import keras.utils as ku\n","\n","from nltk.translate import bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","\n","folder_dir = \"/content/gdrive/My Drive/Exjobb/\"\n","data_dir_drugs = folder_dir + \"drugsCom_raw/\"\n","baseline_dir = folder_dir + \"baseline/\"\n","sugg_dir = folder_dir + \"suggested alternative/\"\n","dong_dir = folder_dir + \"dong_code/\"\n","hu_dir = folder_dir + \"hu_code/\"\n","\n","import sys\n","sys.path.insert(0, folder_dir + \"keras_lstm_vae-master\")\n","from lstm_vae.vae import create_lstm_vae\n","\n","def print_data_stats(data, msg):\n","  print(msg)\n","  print(\"Size of the data set:\", data.shape)\n","  print(\"Number of unique drugs:\", len(set(data[:,0])))\n","  c_drug = Counter(data[:,0])\n","  print(\"Top 15 most frequent drugs (and their count):\", c_drug.most_common(15))\n","  print(\"Number of unique conditions:\", len(set(data[:,1])))\n","  c_cond = Counter(data[:,1])\n","  print(\"Top 15 most frequent conditions (and their count):\", c_cond.most_common(15))  \n","  print(\"Stats around number of characters in the data set\")\n","  lengths = [len(x) for x in data[:,2]]\n","  print(\"- Maximum number of characters in a drug review:\", np.max(lengths))\n","  print(\"- Minimum number of characters in a drug review:\", np.min(lengths))\n","  print(\"- Average number of characters in a drug review:\", np.mean(lengths))\n","  print(\"- Standard deviation aruond number of characters in a drug review:\", np.std(lengths))\n","\n","training = np.array(pd.read_csv(data_dir_drugs + \"drugsComTrain_raw.tsv\", sep = \"\\t\").fillna(-1))[:,1:]  # Remove the columns containing the indices for the drug reviews\n","testing = np.array(pd.read_csv(data_dir_drugs + \"drugsComTest_raw.tsv\", sep = \"\\t\").fillna(-1))[:,1:]  # Remove the columns containing the indices for the drug reviews\n","data_before = np.vstack((training, testing))\n","\n","print_data_stats(data_before, \"##### Basic stats about the data set w.r.t. drugs and diseases #####\")\n","plt.hist([len(x) for x in data_before[:,2]], 1000)\n","plt.show()\n","\n","def is_valid(sample):\n","  no_parsing_error_or_empty = not \"</span>\" in sample[1] if isinstance(sample[1], str) else sample[1]!=-1\n","  if not no_parsing_error_or_empty:\n","    return False\n","  \n","  connected_with_review = sample[0].lower() in sample[2].lower() or sample[1].lower() in sample[2].lower() or \"\".join([x[0] for x in sample[1].split()]).lower() in sample[2].lower()\n","  if not connected_with_review:\n","    return False\n","  \n","  acceptable_size_of_drug_review = 400<=len(sample[2]) and len(sample[2])<=500\n","  if not acceptable_size_of_drug_review:\n","    return False\n","  \n","  satisfying_usefulcount_threshold = 10<=sample[5]\n","  if not satisfying_usefulcount_threshold:\n","    return False\n","  \n","  return True\n","\n","def duplicate_free(data):\n","  present = defaultdict(lambda: (False, -1))\n","  new_data = []\n","  \n","  for entry in data:\n","    key = (entry[1], entry[2], entry[3])\n","    if (not present[key][0]) and entry[0] in entry[2]:\n","      new_data.append(entry)\n","      present[key] = (True, len(new_data) - 1)\n","    elif entry[0] in entry[2]:\n","      if new_data[present[key][1]][0] in entry[2]:\n","        new_data.append(entry)\n","      else:\n","        new_data[present[key][1]][0] = entry[0]\n","  \n","  return np.array(new_data)\n","\n","def free_from_infrequents(data, min_count = 10):\n","  drug_counts = Counter(data[:,0])\n","  cond_counts = Counter(data[:,1])\n","  \n","  new_data = []\n","  for entry in data:\n","    if drug_counts[entry[0]]>=min_count and cond_counts[entry[1]]>=min_count:\n","      new_data.append(entry)\n","    \n","  return np.array(new_data)\n","\n","training[:,2] = np.array([unescape(sample[1:-1]) for sample in training[:,2]])\n","training = free_from_infrequents(duplicate_free(np.array([sample for sample in training if is_valid(sample)])))\n","testing[:,2] = np.array([unescape(sample[1:-1]) for sample in testing[:,2]])\n","testing = free_from_infrequents(duplicate_free(np.array([sample for sample in testing if is_valid(sample)])))\n","\n","print_data_stats(training, \"##### Basic stats about the training data set w.r.t. drugs and diseases #####\")\n","print(training, end = \"\\n\\n\")\n","print_data_stats(testing, \"##### Basic stats about the testing data set w.r.t. drugs and diseases #####\")\n","print(testing, end = \"\\n\\n\")\n","\n","data_after = np.vstack((training, testing))\n","plt.hist([len(x) for x in data_after[:,2]], 1000)\n","plt.show()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["##### Basic stats about the data set w.r.t. drugs and diseases #####\n","Size of the data set: (215063, 6)\n","Number of unique drugs: 3671\n","Top 15 most frequent drugs (and their count): [('Levonorgestrel', 4930), ('Etonogestrel', 4421), ('Ethinyl estradiol / norethindrone', 3753), ('Nexplanon', 2892), ('Ethinyl estradiol / norgestimate', 2790), ('Ethinyl estradiol / levonorgestrel', 2503), ('Phentermine', 2085), ('Sertraline', 1868), ('Escitalopram', 1747), ('Mirena', 1673), ('Implanon', 1506), ('Gabapentin', 1415), ('Bupropion', 1369), ('Miconazole', 1344), ('Venlafaxine', 1338)]\n","Number of unique conditions: 917\n","Top 15 most frequent conditions (and their count): [('Birth Control', 38436), ('Depression', 12164), ('Pain', 8245), ('Anxiety', 7812), ('Acne', 7435), ('Bipolar Disorde', 5604), ('Insomnia', 4904), ('Weight Loss', 4857), ('Obesity', 4757), ('ADHD', 4509), ('Diabetes, Type 2', 3362), ('Emergency Contraception', 3290), ('High Blood Pressure', 3104), ('Vaginal Yeast Infection', 3085), ('Abnormal Uterine Bleeding', 2744)]\n","Stats around number of characters in the data set\n","- Maximum number of characters in a drug review: 10787\n","- Minimum number of characters in a drug review: 3\n","- Average number of characters in a drug review: 458.62074833885885\n","- Standard deviation aruond number of characters in a drug review: 240.99466583956993\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwxBvAAAMQ7wBADAM8QYAwDDEGwAAw/w/rNSu62WE/YMAAAAASUVORK5CYII=\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["##### Basic stats about the training data set w.r.t. drugs and diseases #####\n","Size of the data set: (1604, 6)\n","Number of unique drugs: 75\n","Top 15 most frequent drugs (and their count): [('Lexapro', 62), ('Zoloft', 59), ('Cymbalta', 56), ('Mirena', 49), ('Belviq', 46), ('Chantix', 42), ('Pristiq', 41), ('Lyrica', 39), ('Suboxone', 37), ('Xanax', 33), ('Celexa', 33), ('Tramadol', 33), ('Contrave', 32), ('Prozac', 32), ('Klonopin', 31)]\n","Number of unique conditions: 47\n","Top 15 most frequent conditions (and their count): [('Depression', 246), ('Anxiety', 134), ('Bipolar Disorde', 123), ('Birth Control', 117), ('Pain', 83), ('Weight Loss', 79), ('Obesity', 67), ('ibromyalgia', 66), ('ADHD', 59), ('Insomnia', 57), ('Smoking Cessation', 42), ('Panic Disorde', 40), ('Anxiety and Stress', 39), ('Diabetes, Type 2', 39), ('Opiate Dependence', 37)]\n","Stats around number of characters in the data set\n","- Maximum number of characters in a drug review: 500\n","- Minimum number of characters in a drug review: 400\n","- Average number of characters in a drug review: 452.08977556109727\n","- Standard deviation aruond number of characters in a drug review: 29.46094113513825\n","[['Lithium' 'Bipolar Disorde'\n","  \"I appreciate Lithium. Although my thyroid level is low, a supplement helps to equalize this problem. I've been through at least 20 different medications to stabilize my Bipolar diagnosis. I always wanted to be of normal state of mind. Lithium has allowed me to be equally yoked with myself. 300mg ER in the evening. 100mg of Seroquel in the evening. 20mg of  Cymbalta in the morning! I'm set! If I'm feeling anxiety I can add Busper or Loranzapam.\"\n","  10.0 'August 23, 2016' 27]\n"," ['Lyrica' 'Neuropathic Pain'\n","  'I was diagnosed with adult onset Diabetes last Dec. I started on\\r\\r\\nMetformin 750 and almost immediately my fasting glucose dropped\\r\\r\\nto 94. That is what it has been since but I have been bothered with\\r\\r\\nneuropathy for  months. I tried Lyrica for 3 months and it did\\r\\r\\nabsolutely nothing for the pain. I am presently taking gabapentin\\r\\r\\n300 mg at bedtime and it helps slightly. The cost for the Lyrica\\r\\r\\nwas money out the window.'\n","  1.0 'July 18, 2015' 13]\n"," ['Qsymia' 'Weight Loss'\n","  'My Dr agreed to over see putting me on Qsymia because he watched as I devotedly pursued everything else to no avail. I have now been on this for 1 week and have dropped 3 lbs. I have 60 to go and have all the patience in the world as long as I see progress. I do get tired midday laydown, ten minutes get up, I do get constipated but take those probiotic gummies that seem to help. I crave sweet but nothing really sounds good. I plan to start walking just a mile daily.'\n","  9.0 'February 24, 2013' 46]\n"," ...\n"," ['Lithium' 'Bipolar Disorde'\n","  'Lithium was a God send. It elevated my mood to prevent suicidal thoughts and prevented manic episodes. I had to stop taking it because I had urinary problems unassociated with the lithium, but which were taxing my kidneys and my doctor suggested I stop taking it to prevent further damage.  It was hard to stop taking because it worked so well for me.  I miss it.  I had no other symptoms except I liked water a lot more.'\n","  7.0 'March 30, 2015' 32]\n"," ['Sertraline' 'Depression'\n","  \"I took Sertraline for two months after a short period of depression.\\r\\r\\nStarted with stomach cramps and terrible diarrohea. Could not think at all. Began to have difficulty in reading and writing. Became agressive and unpleasant to be around. Felt like all my emotions and cognitive abilities had been switched off. Reactions became so slow that I stopped driving out of fear of killing someone. Became paranoid. It's awful.\"\n","  1.0 'June 4, 2016' 23]\n"," ['Methadone' 'Pain'\n","  \"I was on oxycontin 40mg 2x a day but had to increase its strength as time passed. Then the doctor put me on Methadone 10mg 4 x a day. This been effective without any increase in dosage over the last year. I am now trying an additional drug with it called Lyrica 150mg 2 x a day. Now almost pain free, only break through pain occasionally.  Before, life was not really anything to look forward too, just pain, pain and more pain. I couldn't even sleep. Not so now with Methadone.\"\n","  8.0 'July 25, 2008' 44]]\n","\n","##### Basic stats about the testing data set w.r.t. drugs and diseases #####\n","Size of the data set: (271, 6)\n","Number of unique drugs: 23\n","Top 15 most frequent drugs (and their count): [('Cymbalta', 17), ('Lexapro', 17), ('Chantix', 16), ('Contrave', 15), ('Celexa', 14), ('Zoloft', 14), ('Mirena', 13), ('Viibryd', 13), ('Pristiq', 12), ('Victoza', 12), ('Nexplanon', 12), ('Paxil', 12), ('Belviq', 11), ('Topamax', 11), ('Latuda', 10)]\n","Number of unique conditions: 18\n","Top 15 most frequent conditions (and their count): [('Depression', 59), ('Birth Control', 28), ('Anxiety', 23), ('Bipolar Disorde', 21), ('Insomnia', 21), ('Obesity', 17), ('Smoking Cessation', 16), ('Anxiety and Stress', 15), ('Weight Loss', 13), ('Emergency Contraception', 10), ('ibromyalgia', 9), ('Diabetes, Type 2', 9), ('Migraine Prevention', 9), ('Acne', 6), ('Generalized Anxiety Disorde', 6)]\n","Stats around number of characters in the data set\n","- Maximum number of characters in a drug review: 500\n","- Minimum number of characters in a drug review: 400\n","- Average number of characters in a drug review: 452.49446494464945\n","- Standard deviation aruond number of characters in a drug review: 28.394281276615555\n","[['Contrave' 'Obesity'\n","  'Been on Contrave for 30 days. I was 283 at 5\\'7 but now 272. Am disappointed b/c I did a 180 degree change on my diet, exercised daily and only lost 11 pounds in 30 days. I am going in the right direction. I didn\\'t have the constipation or nausea. I am pretty \"foggy\" still. But I have thyroid issues and have an appt. for that on the 23rd of February and hoping to get regulated and maybe I\\'ll have more success at losing weight. I\\'m not giving up though!'\n","  9.0 'February 3, 2016' 23]\n"," ['Latuda' 'Bipolar Disorde'\n","  'Relieved symptoms of severe depression but caused terrible, debilitating dry eyes.  I have mild dry eye disease under normal circumstances, and dry eyes are *not* listed as a side effect for Latuda.  It got to the point though where I was unable to do anything because of my dry eye discomfort.  I got severely tense and anxious, which kind of negated any positive effect from the Latuda.  So, we stopped it, and my dry eyes went away.'\n","  5.0 'March 18, 2017' 11]\n"," ['Pristiq' 'Depression'\n","  'I was on my 4th try on a antidepressant and was feeling very discouraged. I had many side effects from the other medicines such as sleepiness, headaches, overeating, agitation, and crying spells. My therapist gave me Pristiq. I read about the side effects and was not looking forward to headaches. I took it and had no side effects. On my second day I was doing a lot more things and felt a lot better. Thank God!'\n","  8.0 'May 17, 2012' 21]\n"," ...\n"," ['Chantix' 'Smoking Cessation'\n","  'I took Chantix according to the directions for 1 month and I have been smoke free for over a year.  Not only did Chantix help me quit, but I have not had any desire to smoke again.   Chantix is amazing.  I tried quitting with the patch, gum, nicotine inhaler, hypnosis, will power, and Zyban (Wellbutrin) and NOTHING ever worked for more then a month or two.  I would recommend Chantix to EVERYONE and ANYONE who is serious about quitting.  IT WORKS!'\n","  10.0 'December 27, 2008' 13]\n"," ['Mirena' 'Birth Control'\n","  \"I have been very happy with Mirena. It was inserted at my 6 week post-partum appointment. I was nervous but felt nothing. It felt like a pap smear.  I did have spotting for about 6 weeks after. I started a diet program two weeks after insertion, and I have lost 21 lbs in the last 6 weeks, so don't believe it when people tell you that they gained a whole bunch of weight after insertion. \\r\\r\\n\\r\\r\\nI have no complaints, and I would recommend Mirena to anyone.\"\n","  10.0 'February 25, 2009' 190]\n"," ['Cymbalta' 'Depression'\n","  \"I have been on Cymbalta for a year. Has helped with depression and overall my moods have been better. It doesn't take much to make me sad, angry, or to cry though.  I suffer from constipation, dry mouth, decreased libido, very hard to get orgasms, nausea, forgetfulness and a few other minor side effects. Wish they (most antidepressants) weren't so hard to go off of. I seem to go deeper into depression with any attempts to go off the medicines.\"\n","  7.0 'April 27, 2009' 25]]\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"3kMb_dWApZuT","colab_type":"code","outputId":"c5680095-cc72-4476-d0db-532e4fd65246","executionInfo":{"status":"error","timestamp":1552998037245,"user_tz":-60,"elapsed":50131,"user":{"displayName":"Sylwester Liljegren","photoUrl":"","userId":"12611084800088710033"}},"colab":{"base_uri":"https://localhost:8080/","height":1139}},"cell_type":"code","source":["##### Long Short-Term Memory network: The baseline model - Preparation: Training/optimizing of the Long Short-Term Memory network #####\n","def is_valid_for_baseline(sample, training = True):\n","  if training:\n","    return True\n","  else:\n","    return True\n","\n","# Retrieve drug reviews from the data set\n","baseline_train = np.array([sample for sample in training if \n","                           is_valid_for_baseline(sample)])[:,2]\n","baseline_test = np.array([sample for sample in testing if \n","                          is_valid_for_baseline(sample, False)])[:,2]\n","\n","class LSTM_model:\n","  def __init__(self, word_level = False, embedding_size = 100, num_units = 250, drop_out = 0.1):\n","    self.word_level = word_level\n","    self.tokenizer = Tokenizer(char_level = not self.word_level)\n","    self.max_sequence_len = None\n","    \n","    self.embedding_size = embedding_size\n","    self.num_units = num_units\n","    self.drop_out = drop_out\n","    self.model = None\n","  \n","  def __preprocess(self, train_data, verbose):\n","    if verbose:\n","      print(\"Preprocessing the data for the LSTM model...\")\n","\n","    self.tokenizer.fit_on_texts(train_data)\n","    num_tokens = len(self.tokenizer.word_index) + 1\n","\n","    if verbose:\n","      print(num_tokens)\n","\n","    input_sequences = []\n","    for review in train_data:\n","      token_list = self.tokenizer.texts_to_sequences([review])[0]\n","      for i in range(1, len(token_list)):\n","          n_gram_sequence = token_list[:i+1]\n","          input_sequences.append(n_gram_sequence)\n","\n","    if verbose:\n","      print(len(input_sequences))\n","    \n","    self.max_sequence_len = max(len(x) for x in input_sequences)\n","    input_sequences = np.array(pad_sequences(input_sequences,\n","                                             maxlen = self.max_sequence_len, \n","                                             padding='pre'))\n","    \n","    predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n","    label = ku.to_categorical(label, num_classes = num_tokens)\n","    \n","    return predictors, label\n","  \n","  def fit(self, train_data, num_epochs = 1, verbose = True, save = False):\n","    # Preparation of the data\n","    predictors, label = self.__preprocess(train_data, verbose)\n","    num_tokens = len(self.tokenizer.word_index) + 1\n","    \n","    if verbose:\n","      print(\"Done with preparing the data for the LSTM model!\", end=\"\\n\\n\")\n","    \n","    # Definition and training of the model\n","    if verbose:\n","      print(\"Training the LSTM model...\")\n","\n","    input_len = self.max_sequence_len - 1\n","\n","    self.model = Sequential()\n","    self.model.add(Embedding(num_tokens, self.embedding_size, input_length=input_len))\n","    self.model.add(LSTM(self.num_units))\n","    self.model.add(Dropout(self.drop_out))\n","    self.model.add(Dense(num_tokens, activation='softmax'))\n","\n","    self.model.compile(loss='categorical_crossentropy', optimizer='adam')\n","    self.model.fit(predictors, label, epochs = num_epochs, verbose = 1 if verbose else 0)\n","    \n","    if save:\n","      if verbose:\n","        print(\"Done with training the LSTM model!\", end=\"\\n\\n\")\n","\n","      if verbose:\n","        print(\"Saving the model...\")\n","\n","      model_path = baseline_dir + \"LSTM_\" + (\"word\" if self.word_level else \"char\") + \"_embedd-\" + str(self.embedding_size) + \"_units-\" + str(self.num_units) + \"_dropo-\" + str(self.drop_out) + \".h5\"\n","      self.model.save(model_path)\n","\n","      if verbose and save:\n","        print(\"Model saved! It has the following path:\", model_path)\n","  \n","  def generate(self, seed_text, next_tokens):\n","    for j in range(next_tokens):\n","      token_list = self.tokenizer.texts_to_sequences([seed_text])[0]\n","      token_list = pad_sequences([token_list], maxlen = self.max_sequence_len - 1, padding='pre')\n","      predicted = self.model.predict_classes(token_list, verbose=0)\n","      \n","      output_word = \"\"\n","      for word, index in self.tokenizer.word_index.items():\n","        if index == predicted:\n","          output_word = word\n","          break\n","        seed_text += (\" \" if self.word_level else \"\") + output_word\n","    \n","    return seed_text\n","\n","print(baseline_train.shape)\n","# Example commands to both train- and run the above implementation\n","baseline_model = LSTM_model(word_level = False, embedding_size = 500, num_units = 750, drop_out = 0)\n","baseline_model.fit(baseline_train, 1)\n","review = np.random.choice(baseline_train)\n","print(review)\n","print(baseline_model.generate(review[:15], len(review[15:])))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["(1604,)\n","Preprocessing the data for the LSTM model...\n","69\n","723548\n","Done with preparing the data for the LSTM model!\n","\n","Training the LSTM model...\n","Epoch 1/1\n","   352/723548 [..............................] - ETA: 14:09:29 - loss: 3.8911"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-3cf029109c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# Example commands to both train- and run the above implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mbaseline_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-3cf029109c4e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, num_epochs, verbose, save)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"rMWFYRglKY1x","colab_type":"code","outputId":"d4d95c3c-501b-4bf6-a7f2-0a75c763f22b","colab":{"base_uri":"https://localhost:8080/","height":1243},"executionInfo":{"status":"error","timestamp":1553000773646,"user_tz":-60,"elapsed":6716,"user":{"displayName":"Sylwester Liljegren","photoUrl":"","userId":"12611084800088710033"}}},"cell_type":"code","source":["##### SUGGESTED ALTERNATIVE - Preparation: Training/optimizing of the recurrent variational autoencoder #####\n","def is_valid_for_suggestion(sample, training = True):\n","  if training:\n","    return True\n","  else:\n","    return True\n","\n","sugg_train = np.array([sample for sample in training if is_valid_for_suggestion(sample)])[:,:-2]\n","sugg_test = np.array([sample for sample in testing if is_valid_for_suggestion(sample, False)])[:,:-2]\n","\n","class suggested_alternative:\n","  def __init__(self, word_level = False):\n","    self.word_level = word_level\n","    self.tokenizer = Tokenizer(char_level = not self.word_level)\n","    self.max_sequence_len = None\n","    \n","    # Settings for the recurrent variational autoencoder\n","    self.encoder = None\n","    self.decoder = None\n","    \n","    # Settings for the collaborative filtering algorithm\n","    self.cf = None\n","    \n","  def __preprocess(self, train_data, verbose = True):\n","    if verbose:\n","      print(\"Preprocessing the data for the LSTM model...\")\n","    \n","    self.tokenizer.fit_on_texts(train_data)\n","    num_tokens = len(self.tokenizer.word_index) + 1\n","    \n","    if verbose:\n","      print(num_tokens)\n","    \n","    input_sequences = []\n","    for review in train_data:\n","      input_sequence = []\n","      token_list = self.tokenizer.texts_to_sequences([review])[0]\n","      for i in range(1, len(token_list)):\n","          n_gram_sequence = token_list[:i+1]\n","          input_sequence.append(n_gram_sequence)\n","      input_sequences.append(input_sequence)\n","    \n","    if verbose:\n","      print(len(input_sequences))\n","    \n","    self.max_sequence_len = max(len(input_seq) for input_seq in input_sequences)\n","    input_sequences = np.array(pad_sequences([pad_sequences(input_seq,\n","                                             maxlen = self.max_sequence_len,\n","                                             padding='pre') for input_seq in input_sequences], \n","                                             maxlen = self.max_sequence_len,\n","                                             padding='pre'))\n","    \n","    return input_sequences\n","  \n","  def fit(self, train_data, verbose = True):\n","    # One-hot encoding of both the drugs and conditions associated with the reviews\n","    \"\"\"onehot_drugs = OneHotEncoder().fit_transform(train_data[:,0].reshape(-1, 1))\n","    onehot_conds = OneHotEncoder().fit_transform(train_data[:,1].reshape(-1, 1))\"\"\"\n","    \n","    # Transforming the review texts into latent numericals vectors\n","    self.__fit_lstm(self.__preprocess(train_data[:,2]))\n","    self.encoder = Model()\n","  \n","  def __fit_lstm(self, train_data):\n","    print(train_data.shape)\n","    lstm_vae, _, _ = create_lstm_vae(train_data.shape[-1], train_data.shape[1], 32, 250, 1)\n","    lstm_vae.summary()\n","    lstm_vae.fit(train_data)\n","  \n","  def __fit_cf(self, train_data):\n","    return train_data\n","    \n","  def generate(self, x):\n","    return x\n","\n","print(sugg_train.shape)\n","# Example commands to both train- and run the above implementation\n","suggested_model = suggested_alternative(True)\n","suggested_model.fit(sugg_train)\n","review = np.random.choice(sugg_train)\n","print(review)\n","print(sugg_model.generate(review[:15], len(review[15:])))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["(1604, 4)\n","Preprocessing the data for the LSTM model...\n","6679\n","1604\n","(1604, 110, 110)\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_27 (InputLayer)           (None, 110, 110)     0                                            \n","__________________________________________________________________________________________________\n","lstm_43 (LSTM)                  (None, 250)          361000      input_27[0][0]                   \n","__________________________________________________________________________________________________\n","dense_30 (Dense)                (None, 1)            251         lstm_43[0][0]                    \n","__________________________________________________________________________________________________\n","dense_31 (Dense)                (None, 1)            251         lstm_43[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 1)            0           dense_30[0][0]                   \n","                                                                 dense_31[0][0]                   \n","__________________________________________________________________________________________________\n","repeat_vector_27 (RepeatVector) (None, 110, 1)       0           lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_44 (LSTM)                  (None, 110, 250)     252000      repeat_vector_27[0][0]           \n","__________________________________________________________________________________________________\n","lstm_45 (LSTM)                  (None, 110, 110)     158840      lstm_44[0][0]                    \n","==================================================================================================\n","Total params: 772,342\n","Trainable params: 772,342\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-7699aebaada3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# Example commands to both train- and run the above implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0msuggested_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuggested_alternative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0msuggested_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msugg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msugg_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-7699aebaada3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, verbose)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Transforming the review texts into latent numericals vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-7699aebaada3>\u001b[0m in \u001b[0;36m__fit_lstm\u001b[0;34m(self, train_data)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mlstm_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_lstm_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mlstm_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mlstm_vae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__fit_cf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mindices_for_conversion_to_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"metadata":{"id":"TDF3hTtOwdW4","colab_type":"code","colab":{}},"cell_type":"code","source":["##### MODEL PROPOSED BY DONG ET AL. - Preparation: Training/optimizing of the model proposed by Dong et al. #####\n","def is_valid_for_dong(sample, training = True):\n","  if training:\n","    return True\n","  else:\n","    return True\n","\n","class dong_model:\n","  def __init__(self):\n","    pass\n","  \n","  def fit(self, train_data):\n","    pass\n","  \n","  def generate(self, x):\n","    return x\n","\n","# TROLOLOLOLOL...\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"56-t3EwZwvJW","colab_type":"code","colab":{}},"cell_type":"code","source":["##### MODEL PROPOSED BY HU ET AL. - Preparation: Training/optimizing of the model proposed by Hu et al. #####\n","def is_valid_for_hu(sample, training = True):\n","  if training:\n","    return True\n","  else:\n","    return True\n","\n","class hu_model:\n","  def __init__(self):\n","    pass\n","  \n","  def fit(self, train_data):\n","    return train_data\n","  \n","  def generate(self, x):\n","    return x\n","  \n","# TROLOLOLOLOL...\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SXMNVR-Ww3f_","colab_type":"code","outputId":"1d24bbc9-4f1d-4df2-feef-bbacb20af8f4","executionInfo":{"status":"ok","timestamp":1553008209144,"user_tz":-60,"elapsed":758,"user":{"displayName":"Sylwester Liljegren","photoUrl":"","userId":"12611084800088710033"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["##### THE FINAL RUMLBE EXPERIMENT - The killer moment! #####\n","\n","def get_bleu_score(review, test_data, rating_span = 5):\n","  try:\n","    candidate = review[2].lower().split()\n","    references = [ref_review[2].lower().split() for ref_review in test_data if (ref_review[[1,3]]==review[[1,3]]).all()]\n","    return bleu(references, candidate, smoothing_function = SmoothingFunction().method4)\n","  except KeyError as e:\n","    print(\"WARNING: No reference translations were obtainable for the following review:\")\n","    print(review)\n","    return -1\n","\n","# TODO\n","i = np.random.randint(testing.shape[0])\n","print(get_bleu_score(testing[i], testing[[j for j in range(testing.shape[0]) if j!=i]]))\n","\n","# ROFLOLOLOLOLOLOLOL...\n"],"execution_count":64,"outputs":[{"output_type":"stream","text":["0.11957185526971167\n"],"name":"stdout"}]}]}